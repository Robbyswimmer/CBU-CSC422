{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 1: Introduction to Linear Regression\n",
    "\n",
    "**Name:** [Your Name Here]  \n",
    "**Student ID:** [Your Student ID]  \n",
    "**Date:** [Today's Date]  \n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome to your first machine learning assignment! In this notebook, you'll journey from mathematical foundations to practical implementation of linear regression. You'll build your own linear regression from scratch, then compare it with professional ML libraries.\n",
    "\n",
    "**Learning Goals:**\n",
    "- Understand linear regression mathematics\n",
    "- Implement gradient descent from scratch\n",
    "- Apply ML to real housing price data\n",
    "- Reflect on ML vs. traditional programming\n",
    "\n",
    "**Estimated Time:** 2 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Mathematical Foundation (30 minutes)\n",
    "\n",
    "Before we code, let's understand the mathematics behind linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "NumPy version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression as SklearnLinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understanding the Linear Equation\n",
    "\n",
    "Linear regression finds the best line through data points. For one feature:\n",
    "\n",
    "**y = mx + b**\n",
    "\n",
    "For multiple features:\n",
    "\n",
    "**y = θ₀ + θ₁x₁ + θ₂x₂ + ... + θₙxₙ**\n",
    "\n",
    "Or in vector form: **y = X·θ**\n",
    "\n",
    "Where:\n",
    "- **y** = predicted value\n",
    "- **X** = feature matrix\n",
    "- **θ** = parameters (weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (50, 1)\n",
      "Target shape: (50,)\n"
     ]
    }
   ],
   "source": [
    "# Let's create some simple synthetic data to visualize linear regression\n",
    "np.random.seed(42)\n",
    "X_simple = np.random.rand(50, 1) * 10  # 50 random points between 0 and 10\n",
    "y_simple = 2.5 * X_simple.flatten() + 1.0 + np.random.randn(50) * 1.5  # y = 2.5x + 1 + noise\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_simple, y_simple, alpha=0.6, color='blue', label='Data Points')\n",
    "plt.xlabel('X (Feature)')\n",
    "plt.ylabel('y (Target)')\n",
    "plt.title('Simple Linear Relationship with Noise')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Data shape: {X_simple.shape}\")\n",
    "print(f\"Target shape: {y_simple.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Cost Function\n",
    "\n",
    "We need to measure how \"wrong\" our predictions are. The **Mean Squared Error (MSE)** cost function is:\n",
    "\n",
    "**J(θ) = (1/2m) × Σ(hθ(x⁽ⁱ⁾) - y⁽ⁱ⁾)²**\n",
    "\n",
    "Where:\n",
    "- **m** = number of training examples\n",
    "- **hθ(x⁽ⁱ⁾)** = prediction for example i\n",
    "- **y⁽ⁱ⁾** = actual value for example i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_cost(X, y, theta):\n    \"\"\"\n    Compute the mean squared error cost function.\n    \n    Parameters:\n    X (array): Feature matrix with bias column\n    y (array): Target values\n    theta (array): Parameters [bias, weight1, weight2, ...]\n    \n    Returns:\n    cost (float): Mean squared error\n    \"\"\"\n    m = len(y)  # number of examples\n    \n    # TODO: Calculate predictions using X @ theta (matrix multiplication)\n    predictions = None  # Replace None with your code\n    \n    # TODO: Calculate errors (predictions - actual values)\n    errors = None  # Replace None with your code\n    \n    # TODO: Square the errors\n    squared_errors = None  # Replace None with your code\n    \n    # TODO: Calculate mean squared error: (1/2m) * sum of squared errors\n    cost = None  # Replace None with your code\n    \n    return cost\n\n# Test the cost function when you're done\n# Add bias column to X_simple\nX_simple_with_bias = np.column_stack([np.ones(X_simple.shape[0]), X_simple])\n\n# Test with random parameters\ntest_theta = np.array([0.0, 1.0])  # [bias, weight]\n\n# TODO: Uncomment the next line after implementing the function\n# test_cost = compute_cost(X_simple_with_bias, y_simple, test_theta)\n# print(f\"Test cost with theta=[0, 1]: {test_cost:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Gradient Descent\n",
    "\n",
    "To minimize the cost function, we use **gradient descent**. We update parameters iteratively:\n",
    "\n",
    "**θⱼ := θⱼ - α × (∂J(θ)/∂θⱼ)**\n",
    "\n",
    "For linear regression, the gradient is:\n",
    "\n",
    "**∂J(θ)/∂θⱼ = (1/m) × Σ(hθ(x⁽ⁱ⁾) - y⁽ⁱ⁾) × xⱼ⁽ⁱ⁾**\n",
    "\n",
    "Where **α** is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_gradients(X, y, theta):\n    \"\"\"\n    Compute gradients for gradient descent.\n    \n    Parameters:\n    X (array): Feature matrix with bias column\n    y (array): Target values  \n    theta (array): Current parameters\n    \n    Returns:\n    gradients (array): Gradients for each parameter\n    \"\"\"\n    m = len(y)  # number of examples\n    \n    # TODO: Calculate predictions using X @ theta\n    predictions = None  # Replace None with your code\n    \n    # TODO: Calculate errors (predictions - actual values)\n    errors = None  # Replace None with your code\n    \n    # TODO: Calculate gradients using matrix operations\n    # Hint: The gradient formula is (1/m) * X.T @ errors\n    gradients = None  # Replace None with your code\n    \n    return gradients\n\n# TODO: Test gradient computation after implementing the function\n# Uncomment the lines below:\n# test_gradients = compute_gradients(X_simple_with_bias, y_simple, test_theta)\n# print(f\"Gradients with theta=[0, 1]: {test_gradients}\")\n# print(f\"Gradient for bias: {test_gradients[0]:.4f}\")\n# print(f\"Gradient for weight: {test_gradients[1]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: From-Scratch Implementation (45 minutes)\n",
    "\n",
    "Now let's build our own Linear Regression class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class LinearRegression:\n    \"\"\"\n    Linear Regression implementation using gradient descent.\n    \"\"\"\n    \n    def __init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n        \"\"\"\n        Initialize the Linear Regression model.\n        \n        Parameters:\n        learning_rate (float): Step size for gradient descent\n        max_iterations (int): Maximum number of iterations\n        tolerance (float): Convergence tolerance\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.max_iterations = max_iterations\n        self.tolerance = tolerance\n        self.theta = None\n        self.cost_history = []\n        \n    def _add_bias_column(self, X):\n        \"\"\"\n        Add bias column (column of ones) to feature matrix.\n        \n        Parameters:\n        X (array): Feature matrix\n        \n        Returns:\n        X_with_bias (array): Feature matrix with bias column\n        \"\"\"\n        # TODO: Create a column of ones and add it to the beginning of X\n        # Hint: Use np.ones() and np.column_stack()\n        bias_column = None  # Replace None with your code\n        X_with_bias = None  # Replace None with your code\n        return X_with_bias\n    \n    def fit(self, X, y):\n        \"\"\"\n        Train the linear regression model using gradient descent.\n        \n        Parameters:\n        X (array): Training features\n        y (array): Training targets\n        \"\"\"\n        # Add bias column\n        X_with_bias = self._add_bias_column(X)\n        \n        # Initialize parameters\n        n_features = X_with_bias.shape[1]\n        # TODO: Initialize theta with small random values\n        # Hint: Use np.random.normal(0, 0.01, n_features)\n        self.theta = None  # Replace None with your code\n        \n        # Gradient descent\n        self.cost_history = []\n        \n        for iteration in range(self.max_iterations):\n            # TODO: Compute current cost using the compute_cost function\n            current_cost = None  # Replace None with your code\n            self.cost_history.append(current_cost)\n            \n            # TODO: Compute gradients using the compute_gradients function\n            gradients = None  # Replace None with your code\n            \n            # TODO: Update parameters using gradient descent rule\n            # New theta = old theta - learning_rate * gradients\n            new_theta = None  # Replace None with your code\n            \n            # Check for convergence\n            if np.allclose(self.theta, new_theta, atol=self.tolerance):\n                print(f\"Converged after {iteration + 1} iterations\")\n                break\n                \n            self.theta = new_theta\n            \n            # Print progress every 100 iterations\n            if (iteration + 1) % 100 == 0:\n                print(f\"Iteration {iteration + 1}: Cost = {current_cost:.6f}\")\n    \n    def predict(self, X):\n        \"\"\"\n        Make predictions using the trained model.\n        \n        Parameters:\n        X (array): Features to predict\n        \n        Returns:\n        predictions (array): Predicted values\n        \"\"\"\n        if self.theta is None:\n            raise Exception(\"Model must be trained first. Call fit() method.\")\n        \n        # TODO: Add bias column and make predictions\n        # Hint: Use self._add_bias_column() and matrix multiplication\n        X_with_bias = None  # Replace None with your code\n        predictions = None  # Replace None with your code\n        \n        return predictions\n    \n    def score(self, X, y):\n        \"\"\"\n        Calculate R-squared score.\n        \n        Parameters:\n        X (array): Features\n        y (array): True values\n        \n        Returns:\n        r2 (float): R-squared score\n        \"\"\"\n        y_pred = self.predict(X)\n        \n        # TODO: Calculate R-squared using the formula: 1 - (SS_res / SS_tot)\n        # SS_res = sum of squared residuals = sum((y_true - y_pred)^2)\n        # SS_tot = total sum of squares = sum((y_true - y_mean)^2)\n        ss_res = None  # Replace None with your code\n        ss_tot = None  # Replace None with your code\n        r2 = None  # Replace None with your code\n        \n        return r2\n\nprint(\"LinearRegression class defined successfully!\")\nprint(\"TODO: Complete the missing implementations in the methods above\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Test Your Implementation\n",
    "\n",
    "Let's test your linear regression on the synthetic data we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO: After implementing your LinearRegression class, uncomment and run this code\n\n# Create and train our model\n# print(\"Training our from-scratch Linear Regression...\")\n# our_model = LinearRegression(learning_rate=0.1, max_iterations=1000)\n# our_model.fit(X_simple, y_simple)\n\n# Make predictions\n# y_pred_ours = our_model.predict(X_simple)\n\n# Calculate metrics\n# our_r2 = our_model.score(X_simple, y_simple)\n# our_mse = mean_squared_error(y_simple, y_pred_ours)\n\n# print(f\"\\nOur Model Results:\")\n# print(f\"Final parameters (theta): {our_model.theta}\")\n# print(f\"R² Score: {our_r2:.4f}\")\n# print(f\"MSE: {our_mse:.4f}\")\n# print(f\"Bias (intercept): {our_model.theta[0]:.4f}\")\n# print(f\"Weight (slope): {our_model.theta[1]:.4f}\")\n\nprint(\"TODO: Uncomment the code above after implementing your LinearRegression class\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare with scikit-learn (this will work regardless of your implementation)\nsklearn_model = SklearnLinearRegression()\nsklearn_model.fit(X_simple, y_simple)\ny_pred_sklearn = sklearn_model.predict(X_simple)\n\nsklearn_r2 = sklearn_model.score(X_simple, y_simple)\nsklearn_mse = mean_squared_error(y_simple, y_pred_sklearn)\n\nprint(f\"Scikit-learn Results:\")\nprint(f\"R² Score: {sklearn_r2:.4f}\")\nprint(f\"MSE: {sklearn_mse:.4f}\")\nprint(f\"Bias (intercept): {sklearn_model.intercept_:.4f}\")\nprint(f\"Weight (slope): {sklearn_model.coef_[0]:.4f}\")\n\n# TODO: Uncomment the comparison code below after implementing your model\n# print(f\"\\nComparison:\")\n# print(f\"R² difference: {abs(our_r2 - sklearn_r2):.6f}\")\n# print(f\"MSE difference: {abs(our_mse - sklearn_mse):.6f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Uncomment and complete this visualization code after implementing your model\n\n# Visualize the results\n# plt.figure(figsize=(15, 5))\n\n# # Plot 1: Data and predictions\n# plt.subplot(1, 3, 1)\n# plt.scatter(X_simple, y_simple, alpha=0.6, color='blue', label='Data')\n# plt.plot(X_simple, y_pred_ours, 'r-', label=f'Our Model (R²={our_r2:.3f})', linewidth=2)\n# plt.plot(X_simple, y_pred_sklearn, 'g--', label=f'Scikit-learn (R²={sklearn_r2:.3f})', linewidth=2)\n# plt.xlabel('X (Feature)')\n# plt.ylabel('y (Target)')\n# plt.title('Model Comparison')\n# plt.legend()\n# plt.grid(True, alpha=0.3)\n\n# # Plot 2: Cost function history\n# plt.subplot(1, 3, 2)\n# plt.plot(our_model.cost_history, 'b-', linewidth=2)\n# plt.xlabel('Iteration')\n# plt.ylabel('Cost (MSE)')\n# plt.title('Learning Curve')\n# plt.grid(True, alpha=0.3)\n\n# # Plot 3: Actual vs Predicted\n# plt.subplot(1, 3, 3)\n# min_val = min(y_simple.min(), y_pred_ours.min())\n# max_val = max(y_simple.max(), y_pred_ours.max())\n# plt.scatter(y_simple, y_pred_ours, alpha=0.6, color='red', label='Our Model')\n# plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8, label='Perfect Prediction')\n# plt.xlabel('Actual Values')\n# plt.ylabel('Predicted Values')\n# plt.title('Actual vs Predicted')\n# plt.legend()\n# plt.grid(True, alpha=0.3)\n\n# plt.tight_layout()\n# plt.show()\n\nprint(\"TODO: Uncomment the visualization code above after implementing your LinearRegression class\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Reflection Questions\n",
    "\n",
    "**TODO: Answer these questions in the markdown cells below:**\n",
    "\n",
    "1. How close are your results to scikit-learn's implementation?\n",
    "2. What do you notice about the convergence of the cost function?\n",
    "3. What happens if you change the learning rate? Try different values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer for Question 1:**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer for Question 2:**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer for Question 3:**\n",
    "\n",
    "[TODO: Experiment with different learning rates and write your observations here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Real-World Application (30 minutes)\n",
    "\n",
    "Now let's apply our linear regression to real housing price data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "print(\"Loading California Housing dataset...\")\n",
    "california_data = fetch_california_housing()\n",
    "X_california = california_data.data\n",
    "y_california = california_data.target\n",
    "feature_names = california_data.feature_names\n",
    "\n",
    "print(f\"Dataset shape: {X_california.shape}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Target range: ${y_california.min():.1f} - ${y_california.max():.1f} (in $100K units)\")\n",
    "print(f\"\\nFirst few samples:\")\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df_california = pd.DataFrame(X_california, columns=feature_names)\n",
    "df_california['PRICE'] = y_california\n",
    "print(df_california.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Exploration\n",
    "\n",
    "Let's understand our data before applying machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(df_california.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df_california.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some key relationships\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Select some interesting features to plot\n",
    "interesting_features = ['MedInc', 'HouseAge', 'AveRooms', 'Population', 'AveOccup', 'Latitude']\n",
    "feature_descriptions = {\n",
    "    'MedInc': 'Median income in block',\n",
    "    'HouseAge': 'Median house age in block',\n",
    "    'AveRooms': 'Average rooms per household',\n",
    "    'Population': 'Block population',\n",
    "    'AveOccup': 'Average occupancy',\n",
    "    'Latitude': 'Block latitude'\n",
    "}\n",
    "\n",
    "for i, feature in enumerate(interesting_features):\n",
    "    axes[i].scatter(df_california[feature], df_california['PRICE'], alpha=0.6)\n",
    "    axes[i].set_xlabel(f'{feature} ({feature_descriptions[feature]})')\n",
    "    axes[i].set_ylabel('House Price ($100K)')\n",
    "    axes[i].set_title(f'Price vs {feature}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(df_california[feature], df_california['PRICE'])[0, 1]\n",
    "    axes[i].text(0.05, 0.95, f'r = {correlation:.3f}', \n",
    "                transform=axes[i].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Preprocessing\n",
    "\n",
    "For gradient descent to work well, we need to scale our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_california, y_california, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeature scaling applied:\")\n",
    "print(f\"Original range - min: {X_train.min():.2f}, max: {X_train.max():.2f}\")\n",
    "print(f\"Scaled range - min: {X_train_scaled.min():.2f}, max: {X_train_scaled.max():.2f}\")\n",
    "print(f\"Scaled mean: {X_train_scaled.mean():.6f}, std: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Apply Both Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our from-scratch model\n",
    "print(\"Training our Linear Regression on housing data...\")\n",
    "our_housing_model = LinearRegression(learning_rate=0.1, max_iterations=2000)\n",
    "our_housing_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_ours = our_housing_model.predict(X_train_scaled)\n",
    "y_test_pred_ours = our_housing_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics for our model\n",
    "our_train_r2 = our_housing_model.score(X_train_scaled, y_train)\n",
    "our_test_r2 = our_housing_model.score(X_test_scaled, y_test)\n",
    "our_train_mse = mean_squared_error(y_train, y_train_pred_ours)\n",
    "our_test_mse = mean_squared_error(y_test, y_test_pred_ours)\n",
    "\n",
    "print(f\"\\nOur Model - Housing Data Results:\")\n",
    "print(f\"Training R²: {our_train_r2:.4f}\")\n",
    "print(f\"Test R²: {our_test_r2:.4f}\")\n",
    "print(f\"Training MSE: {our_train_mse:.4f}\")\n",
    "print(f\"Test MSE: {our_test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train scikit-learn model for comparison\n",
    "print(\"Training scikit-learn model...\")\n",
    "sklearn_housing_model = SklearnLinearRegression()\n",
    "sklearn_housing_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_sklearn = sklearn_housing_model.predict(X_train_scaled)\n",
    "y_test_pred_sklearn = sklearn_housing_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "sklearn_train_r2 = sklearn_housing_model.score(X_train_scaled, y_train)\n",
    "sklearn_test_r2 = sklearn_housing_model.score(X_test_scaled, y_test)\n",
    "sklearn_train_mse = mean_squared_error(y_train, y_train_pred_sklearn)\n",
    "sklearn_test_mse = mean_squared_error(y_test, y_test_pred_sklearn)\n",
    "\n",
    "print(f\"Scikit-learn - Housing Data Results:\")\n",
    "print(f\"Training R²: {sklearn_train_r2:.4f}\")\n",
    "print(f\"Test R²: {sklearn_test_r2:.4f}\")\n",
    "print(f\"Training MSE: {sklearn_train_mse:.4f}\")\n",
    "print(f\"Test MSE: {sklearn_test_mse:.4f}\")\n",
    "\n",
    "print(f\"\\nModel Comparison:\")\n",
    "print(f\"Test R² difference: {abs(our_test_r2 - sklearn_test_r2):.6f}\")\n",
    "print(f\"Test MSE difference: {abs(our_test_mse - sklearn_test_mse):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize housing data results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Training predictions\n",
    "axes[0, 0].scatter(y_train, y_train_pred_ours, alpha=0.6, color='red', label='Our Model')\n",
    "axes[0, 0].scatter(y_train, y_train_pred_sklearn, alpha=0.6, color='blue', label='Scikit-learn')\n",
    "min_val = min(y_train.min(), y_train_pred_ours.min())\n",
    "max_val = max(y_train.max(), y_train_pred_ours.max())\n",
    "axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Actual Price ($100K)')\n",
    "axes[0, 0].set_ylabel('Predicted Price ($100K)')\n",
    "axes[0, 0].set_title(f'Training Set Predictions')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Test predictions\n",
    "axes[0, 1].scatter(y_test, y_test_pred_ours, alpha=0.6, color='red', label=f'Our Model (R²={our_test_r2:.3f})')\n",
    "axes[0, 1].scatter(y_test, y_test_pred_sklearn, alpha=0.6, color='blue', label=f'Scikit-learn (R²={sklearn_test_r2:.3f})')\n",
    "min_val = min(y_test.min(), y_test_pred_ours.min())\n",
    "max_val = max(y_test.max(), y_test_pred_ours.max())\n",
    "axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Actual Price ($100K)')\n",
    "axes[0, 1].set_ylabel('Predicted Price ($100K)')\n",
    "axes[0, 1].set_title('Test Set Predictions')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Learning curve\n",
    "axes[1, 0].plot(our_housing_model.cost_history, 'b-', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Cost (MSE)')\n",
    "axes[1, 0].set_title('Learning Curve - Housing Data')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Feature importance (weights)\n",
    "feature_weights = our_housing_model.theta[1:]  # Exclude bias term\n",
    "sorted_indices = np.argsort(np.abs(feature_weights))[::-1]\n",
    "axes[1, 1].bar(range(len(feature_weights)), np.abs(feature_weights)[sorted_indices])\n",
    "axes[1, 1].set_xlabel('Features')\n",
    "axes[1, 1].set_ylabel('Absolute Weight')\n",
    "axes[1, 1].set_title('Feature Importance (|Weights|)')\n",
    "axes[1, 1].set_xticks(range(len(feature_weights)))\n",
    "axes[1, 1].set_xticklabels([feature_names[i] for i in sorted_indices], rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Analysis Questions\n",
    "\n",
    "**TODO: Answer these questions based on your results:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. How well does your model perform on the housing data? What does the R² score tell you?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Which features seem most important for predicting house prices? Look at the feature weights.**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How do training and test performance compare? What does this suggest about your model?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Critical Reflection (15 minutes)\n",
    "\n",
    "Now let's reflect on the bigger picture: How does machine learning differ from traditional programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ML vs Traditional Programming\n",
    "\n",
    "**Traditional Programming:**\n",
    "- We write explicit rules and logic\n",
    "- Input + Program → Output\n",
    "- Deterministic and predictable\n",
    "- Example: `if temperature > 80: recommend_shorts()`\n",
    "\n",
    "**Machine Learning:**\n",
    "- We provide examples and let the algorithm learn patterns\n",
    "- Input + Output → Program (Model)\n",
    "- Statistical and probabilistic\n",
    "- Example: Learn from 10,000 weather/clothing combinations\n",
    "\n",
    "**TODO: Provide a specific example from your housing price prediction experience:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example from Housing Prediction:**\n",
    "\n",
    "**Traditional Programming Approach:**\n",
    "[TODO: Describe how you might write traditional code to estimate house prices]\n",
    "\n",
    "**Machine Learning Approach:**\n",
    "[TODO: Describe how ML learned to predict house prices from your experience]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 When to Use Machine Learning\n",
    "\n",
    "**TODO: Based on your experience, answer these questions:**\n",
    "\n",
    "**1. When would you choose machine learning over traditional programming?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. When would traditional programming be better than machine learning?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What are the main challenges you encountered with machine learning in this assignment?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Limitations of Linear Regression\n",
    "\n",
    "**TODO: Reflect on what you've learned:**\n",
    "\n",
    "**1. What assumptions does linear regression make? When might these be violated?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How could you improve your housing price predictions?**\n",
    "\n",
    "[TODO: Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Experimentation (Optional)\n",
    "\n",
    "If you have extra time, try these experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus 1: Try different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1, 1.0]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = LinearRegression(learning_rate=lr, max_iterations=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    test_r2 = model.score(X_test_scaled, y_test)\n",
    "    results.append((lr, test_r2, len(model.cost_history)))\n",
    "    print(f\"Learning rate {lr}: R² = {test_r2:.4f}, Iterations = {len(model.cost_history)}\")\n",
    "\n",
    "# TODO: What do you observe about different learning rates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations about Learning Rates:**\n",
    "\n",
    "[TODO: Write your observations here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus 2: Feature selection - try using only the most important features\n",
    "# Get the top 5 most important features\n",
    "feature_weights = our_housing_model.theta[1:]  # Exclude bias\n",
    "top_features_idx = np.argsort(np.abs(feature_weights))[::-1][:5]\n",
    "\n",
    "print(f\"Top 5 most important features:\")\n",
    "for i, idx in enumerate(top_features_idx):\n",
    "    print(f\"{i+1}. {feature_names[idx]}: weight = {feature_weights[idx]:.4f}\")\n",
    "\n",
    "# Train model with only top features\n",
    "X_train_top = X_train_scaled[:, top_features_idx]\n",
    "X_test_top = X_test_scaled[:, top_features_idx]\n",
    "\n",
    "top_model = LinearRegression(learning_rate=0.1, max_iterations=1000)\n",
    "top_model.fit(X_train_top, y_train)\n",
    "\n",
    "top_test_r2 = top_model.score(X_test_top, y_test)\n",
    "print(f\"\\nR² with all features: {our_test_r2:.4f}\")\n",
    "print(f\"R² with top 5 features: {top_test_r2:.4f}\")\n",
    "print(f\"Difference: {our_test_r2 - top_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Congratulations! In this assignment, you have:\n",
    "\n",
    "✅ **Understood the mathematics** behind linear regression  \n",
    "✅ **Implemented gradient descent** from scratch  \n",
    "✅ **Built a complete ML pipeline** for housing price prediction  \n",
    "✅ **Compared your implementation** with professional libraries  \n",
    "✅ **Reflected critically** on ML vs traditional programming  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**TODO: Write 2-3 key insights from this assignment:**\n",
    "\n",
    "1. [TODO: Your first key takeaway]\n",
    "2. [TODO: Your second key takeaway]  \n",
    "3. [TODO: Your third key takeaway]\n",
    "\n",
    "### Final Reflection\n",
    "\n",
    "**TODO: Write a brief (100-150 words) final reflection on your experience with this assignment:**\n",
    "\n",
    "[TODO: Your final reflection here]\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment Complete!** \n",
    "\n",
    "Make sure to:\n",
    "1. Save your notebook\n",
    "2. Export as HTML\n",
    "3. Submit both .ipynb and .html files\n",
    "4. Include your name and student ID at the top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}